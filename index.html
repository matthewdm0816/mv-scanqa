<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <!-- 🔄 CHANGED: Updated meta description -->
  <meta name="description" content="Advancing 3D Scene Understanding with MV-ScanQA Multi-View Reasoning Evaluation and TripAlign Pre-training Dataset">
  <!-- 🔄 CHANGED: Updated social media title -->
  <meta property="og:title" content="Advancing 3D Scene Understanding with MV-ScanQA Multi-View Reasoning Evaluation and TripAlign Pre-training Dataset"/>
  <!-- 🔄 CHANGED: Updated social media description -->
  <meta property="og:description" content="A comprehensive study on 3D scene understanding with multi-view reasoning evaluation and pre-training dataset"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <!-- 🔄 CHANGED: Updated Twitter meta tags -->
  <meta name="twitter:title" content="Advancing 3D Scene Understanding with MV-ScanQA Multi-View Reasoning Evaluation and TripAlign Pre-training Dataset">
  <meta name="twitter:description" content="A comprehensive study on 3D scene understanding with multi-view reasoning evaluation and pre-training dataset">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- 🔄 CHANGED: Updated keywords -->
  <meta name="keywords" content="3D scene understanding, multi-view reasoning, computer vision, machine learning, dataset, MV-ScanQA, TripAlign">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- 🔄 CHANGED: Updated title -->
  <title>Advancing 3D Scene Understanding with MV-ScanQA Multi-View Reasoning Evaluation and TripAlign Pre-training Dataset</title>
  <link rel="icon" type="image/x-icon" href="static/images/icon.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="static/js/three.min.js"></script>
  <script src="static/js/OrbitControls.js"></script>
  <script src="static/js/GLTFLoader.js"></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <!-- Add custom styles for progress bar -->
  <style>
    .progress-container {
      position: absolute;
      left: 50%;
      top: 50%;
      transform: translate(-50%, -50%);
      z-index: 10;
      background: rgba(255, 255, 255, 0.95);
      padding: 20px;
      border-radius: 8px;
      box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
      min-width: 300px;
      display: none;
    }
    
    .progress-container .progress {
      margin-top: 10px;
    }
    
    .progress-text {
      text-align: center;
      margin-bottom: 10px;
      font-size: 14px;
      color: #363636;
    }
    
    .progress-note {
      text-align: center;
      margin-top: 10px;
      font-size: 12px;
      color: #7a7a7a;
      font-style: italic;
    }
  </style>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- 🔄 CHANGED: Updated paper title -->
            <h1 class="title is-1 publication-title">Advancing 3D Scene Understanding with MV-ScanQA Multi-View Reasoning Evaluation and TripAlign Pre-training Dataset</h1>
            <div class="is-size-5 publication-authors">
              <!-- 🔄 CHANGED: Updated paper authors -->
              <span class="author-block">
                <a href="https://matthewdm0816.github.io" target="_blank">Wentao Mo</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://sites.google.com/view/qchen2homepage" target="_blank">Qingchao Chen</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="http://39.108.48.32/mipl/yuxinpeng/" target="_blank">Yuxin Peng</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="https://siyuanhuang.com/" target="_blank">Siyuan Huang</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="https://www.csyangliu.com/" target="_blank">Yang Liu</a><sup>1</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <!-- 🔄 CHANGED: Updated institution information -->
                    <span class="author-block"><sup>1</sup>Wangxuan Institute of Computer Technology, Peking University<br></span>
                    <span class="author-block"><sup>2</sup>Beijing Institute for General Artificial Intelligence<br></span>
                    <!-- <span class="author-block">Conference name and year</span> -->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://drive.google.com/file/d/19Ki-2WkpH7KpepwTTFcku6klvGJROuMQ/view?usp=sharing" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- 🔄 CHANGED: Updated supplementary link -->
                    <span class="link-block">
                      <a href="https://drive.google.com/file/d/1rQY_324qqzFmSCced3HRDwuiaOApnztK/view?usp=sharing" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  

                <!-- 🔄 ADDED: MV-ScanQA Dataset link -->
                <span class="link-block">
                  <a href="https://drive.google.com/file/d/1JNka4xBwLrv-L-t2RHndELpte67tiTO2/view?usp=sharing" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-database"></i>
                  </span>
                  <span>MV-ScanQA Dataset</span>
                </a>
              </span>

              <!-- 🔄 ADDED: TripAlign Dataset link -->
              <span class="link-block">
                <a href="https://drive.google.com/file/d/1YXaan3xvmiCQWRfQTBafxyLhMn_7ty-z/view?usp=sharing" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-database"></i>
                </span>
                <span>TripAlign Dataset</span>
              </a>
            </span>

            <!-- Github link -->
            <span class="link-block">
              <a href="https://github.com/" target="_blank"
              class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                <i class="fab fa-github"></i>
              </span>
              <span>Code (Coming Soon)</span>
            </a>
          </span>

          <!-- ArXiv abstract Link -->
          <!-- <span class="link-block">
            <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
            class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
              <i class="ai ai-arxiv"></i>
            </span>
            <span>arXiv</span>
          </a>
        </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The advancement of 3D vision-language (3D VL) learning is hindered by several limitations in existing 3D VL datasets: they rarely necessitate reasoning beyond a close range of objects in single viewpoint, and annotations often link instructions to single objects, missing richer contextual alignments between multiple objects. This significantly curtails the development of models capable of deep, multi-view 3D scene understanding over distant objects. To address these challenges, we introduce <strong>MV-ScanQA</strong>, a novel 3D question answering dataset where 68% of questions explicitly require integrating information from multiple views (compared to less than 7% in existing datasets), thereby rigorously testing multi-view compositional reasoning. To facilitate the training of models for such demanding scenarios, we present <strong>TripAlign</strong> dataset, a large-scale and low-cost 2D-3D-language pre-training corpus containing 1M &lt;2D view, set of 3D objects, text&gt; triplets that explicitly aligns groups of contextually related objects with text, providing richer, view-grounded multi-object multimodal alignment signals than previous single-object annotations. We further develop <strong>LEGO</strong>, a baseline method for the multi-view reasoning challenge in MV-ScanQA, leveraging the strengths of pre-trained 2D LVLMs and TripAlign. Experiments on LEGO show state-of-the-art performance on established benchmarks. Its superior results on MV-ScanQA also expose the limitations of prior models in complex multi-view scenarios, and demonstrate MV-ScanQA and TripAlign's importance in fostering robust 3D vision-language understanding.
            </p>
            
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- MV-ScanQA Dataset Examples -->
<section class="section">
  <!--Temporary disable to make it better-->
  <!-- <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">MV-ScanQA Dataset Examples (Static)</h2>
        <div class="content has-text-justified">
          <p>
            MV-ScanQA challenges models with questions that require reasoning across multiple viewpoints. 
            Below are examples showing how questions necessitate integrating information from different perspectives 
            and distant objects to arrive at the correct answer.
          </p>
        </div>
      </div>
    </div>
    <div class="columns is-centered" style="margin-top: 2rem;">
      <div class="column is-full">
        <figure class="image">
          <img src="static/images/qual-mvscanqa.png"
               alt="MV-ScanQA Dataset Examples" 
               style="max-width: 100%; height: auto; border: 1px solid #ddd; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
        </figure>
        <div class="content has-text-centered" style="margin-top: 1rem;">
          <p class="is-size-6 has-text-grey">
            <em>Figure: Examples from MV-ScanQA showing multi-view questions and their corresponding 3D scenes. 
            Questions are designed to require information integration from multiple viewpoints.</em>
          </p>
        </div>
      </div>
    </div> -->

    <!-- Key Statistics -->
    <div class="columns is-multiline is-centered" style="margin-top: 2rem;">
      <div class="column is-3">
        <div class="box has-text-centered">
          <p class="title is-5 has-text-primary">68%</p>
          <p class="subtitle is-6">Multi-view Questions</p>
        </div>
      </div>
      <div class="column is-3">
        <div class="box has-text-centered">
          <p class="title is-5 has-text-info">3.2k</p>
          <p class="subtitle is-6">Total Questions</p>
        </div>
      </div>
      <div class="column is-3">
        <div class="box has-text-centered">
          <p class="title is-5 has-text-success">2.3</p>
          <p class="subtitle is-6">Average Views Required</p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- MV-ScanQA Dataset Statistics -->
<section class="section" style="background-color: #fafafa;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">MV-ScanQA Dataset Analysis</h2>
        <div class="content has-text-justified">
          <p>
            MV-ScanQA introduces multi-view reasoning challenges by composing questions that require information integration 
            across different viewpoints. Below we present key statistics about the dataset composition and characteristics.
          </p>
        </div>
      </div>
    </div>

    <!-- First Row: Two Figures -->
    <div class="columns is-centered" style="margin-top: 2rem;">
      <!-- Views Distribution -->
      <div class="column is-half">
        <div class="box">
          <h4 class="subtitle is-5 has-text-centered">
            <span class="icon has-text-info"><i class="fas fa-eye"></i></span>
            <span>Number of Views Required Distribution</span>
          </h4>
          <figure class="image">
            <img src="static/images/n_views_distribution_bar.png" 
                 alt="Distribution of number of views required to solve questions" 
                 style="max-width: 100%; height: auto;">
          </figure>
          <p class="has-text-centered has-text-grey is-size-7" style="margin-top: 0.5rem;">
            <em>Distribution showing how many views are needed to answer each question. 
            Higher values indicate more complex multi-view reasoning requirements.</em>
          </p>
        </div>
      </div>

      <!-- Question Type Distribution -->
      <div class="column is-half">
        <div class="box">
          <h4 class="subtitle is-5 has-text-centered">
            <span class="icon has-text-success"><i class="fas fa-chart-pie"></i></span>
            <span>Question Type Distribution</span>
          </h4>
          <figure class="image">
            <img src="static/images/question_types_sorted.png" 
                 alt="Distribution of question types in MV-ScanQA" 
                 style="max-width: 100%; height: auto;">
          </figure>
          <p class="has-text-centered has-text-grey is-size-7" style="margin-top: 0.5rem;">
            <em>Breakdown of question types showing the diversity of reasoning tasks, 
            including counting, spatial relations, and attribute queries.</em>
          </p>
        </div>
      </div>
    </div>

    <!-- Second Row: Word Cloud -->
    <!-- <div class="columns is-centered" style="margin-top: 2rem;">
      <div class="column is-10">
        <div class="box">
          <h4 class="subtitle is-5 has-text-centered">
            <span class="icon has-text-primary"><i class="fas fa-cloud"></i></span>
            <span>Question Word Cloud</span>
          </h4>
          <figure class="image">
            <img src="static/images/scanqa_wordcloud.png" 
                 alt="Word cloud of questions in MV-ScanQA dataset" 
                 style="max-width: 100%; height: auto; display: block; margin: 0 auto;">
          </figure>
          <p class="has-text-centered has-text-grey is-size-7" style="margin-top: 0.5rem;">
            <em>Word cloud visualization of the most frequent terms in MV-ScanQA questions. </em>
          </p>
        </div>
      </div>
    </div> -->

  </div>
</section>


<!-- MV-ScanQA Dataset Showcase -->
<section class="section" id="mvscanqa-showcase">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">MV-ScanQA Interactive Examples</h2>
        <div class="content has-text-justified">
          <p>
            Explore how MV-ScanQA combines multiple single-view questions to create challenging multi-view reasoning tasks. 
            Each example shows how information from different viewpoints must be integrated to answer the composite question.
          </p>
        </div>
      </div>
    </div>

    <!-- Controls -->
    <div class="columns is-centered" style="margin-top: 2rem;">
      <div class="column is-half">
        <div class="field">
          <label class="label">Select Scene</label>
          <div class="control">
            <div class="select is-fullwidth">
              <select id="mvScanQASceneSelector">
                <option value="scene0000_00">Scene 0000_00</option>
                <option value="scene0013_00">Scene 0013_00</option>
                <option value="scene0029_00">Scene 0029_00</option>
              </select>
            </div>
          </div>
        </div>
      </div>
      <div class="column is-half">
        <div class="field">
          <label class="label">Select Question Example</label>
          <div class="control">
            <div class="select is-fullwidth">
              <select id="mvScanQAExampleSelector">
                <!-- Options will be populated dynamically -->
              </select>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Question Composition Display -->
    <div class="box" style="margin-top: 2rem; background-color: #f8f9fa;">
      <h3 class="title is-4 has-text-centered">Question Composition</h3>
      
      <!-- Original Questions -->
      <div class="columns is-multiline">
        <div class="column is-half">
          <div class="box has-background-white">
            <h4 class="subtitle is-5 has-text-primary">
              <span class="icon"><i class="fas fa-question-circle"></i></span>
              Question 1
            </h4>
            <p class="has-text-weight-semibold" id="mvQuestion1">Loading...</p>
            <p class="has-text-grey" style="margin-top: 0.5rem;">
              <span class="tag is-light">Answer:</span> 
              <span id="mvAnswer1">Loading...</span>
            </p>
            <div style="margin-top: 0.5rem;">
              <span class="tag is-info is-light">Objects:</span>
              <span id="mvObjects1" class="has-text-grey-dark"></span>
            </div>
          </div>
        </div>
        
        <div class="column is-half">
          <div class="box has-background-white">
            <h4 class="subtitle is-5 has-text-primary">
              <span class="icon"><i class="fas fa-question-circle"></i></span>
              Question 2
            </h4>
            <p class="has-text-weight-semibold" id="mvQuestion2">Loading...</p>
            <p class="has-text-grey" style="margin-top: 0.5rem;">
              <span class="tag is-light">Answer:</span> 
              <span id="mvAnswer2">Loading...</span>
            </p>
            <div style="margin-top: 0.5rem;">
              <span class="tag is-info is-light">Objects:</span>
              <span id="mvObjects2" class="has-text-grey-dark"></span>
            </div>
          </div>
        </div>
      </div>

      <!-- Arrow pointing down -->
      <div class="has-text-centered" style="margin: 1rem 0;">
        <span class="icon is-large has-text-success">
          <i class="fas fa-arrow-down fa-2x"></i>
        </span>
      </div>

      <!-- Composite Question -->
      <div class="box has-background-success-light">
        <h4 class="subtitle is-5 has-text-success-dark">
          <span class="icon"><i class="fas fa-lightbulb"></i></span>
          Multi-View Question
        </h4>
        <p class="has-text-weight-bold is-size-5" id="mvNewQuestion">Loading...</p>
        <p class="has-text-grey-dark" style="margin-top: 0.5rem;">
          <span class="tag is-success is-light">Answer:</span> 
          <span id="mvNewAnswer" class="has-text-weight-semibold">Loading...</span>
        </p>
        <div style="margin-top: 1rem;">
          <span class="tag is-warning">All Related Objects:</span>
          <span id="mvAllObjects" class="has-text-grey-dark"></span>
        </div>
      </div>

      <!-- View Requirements -->
      <div class="level" style="margin-top: 2rem;">
        <div class="level-item has-text-centered">
          <div>
            <p class="heading">Minimum Views Required</p>
            <p class="title is-4" id="mvViewsRequired">
              <span class="tag is-large is-danger">Loading...</span>
            </p>
          </div>
        </div>
        <div class="level-item has-text-centered">
          <div>
            <p class="heading">View Overlap Score</p>
            <p class="title is-5" id="mvOverlapScore">
              <span class="tag is-medium is-info">Loading...</span>
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<script>
  // MV-ScanQA data structure
  let mvScanQAData = {};
  
  // Load MV-ScanQA annotations
  async function loadMVScanQAAnnotations() {
    try {
      const response = await fetch('static/mvscanqa/sampled_mvscanqa.json');
      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }
      
      const annotations = await response.json();
      console.log(`Loaded ${annotations.length} MV-ScanQA annotations`);
      
      // Process annotations by scene
      mvScanQAData = {};
      
      annotations.forEach((item) => {
        const sceneId = item.scene_id;
        
        if (!mvScanQAData[sceneId]) {
          mvScanQAData[sceneId] = [];
        }
        
        mvScanQAData[sceneId].push(item);
      });
      
      // Update scene selector with actual scenes
      const sceneSelector = document.getElementById('mvScanQASceneSelector');
      sceneSelector.innerHTML = ''; // Clear existing options
      
      // Add options for each scene in the data
      Object.keys(mvScanQAData).sort().forEach(sceneId => {
        const option = document.createElement('option');
        option.value = sceneId;
        option.textContent = sceneId;
        sceneSelector.appendChild(option);
      });
      
      // Select first scene and update examples
      const firstSceneId = Object.keys(mvScanQAData).sort()[0];
      if (firstSceneId) {
        sceneSelector.value = firstSceneId;
        updateMVExampleOptions(firstSceneId);
      }
      
    } catch (error) {
      console.error('Error loading MV-ScanQA annotations:', error);
      loadMVFallbackData();
    }
  }
  
  // Update example options when scene changes
  function updateMVExampleOptions(sceneId) {
    const exampleSelector = document.getElementById('mvScanQAExampleSelector');
    exampleSelector.innerHTML = '';
    
    if (mvScanQAData[sceneId]) {
      mvScanQAData[sceneId].forEach((example, index) => {
        const option = document.createElement('option');
        option.value = index;
        option.textContent = `Example ${index + 1}: ${example.new_question.substring(0, 50)}...`;
        exampleSelector.appendChild(option);
      });
      
      // Load first example
      if (mvScanQAData[sceneId].length > 0) {
        displayMVExample(sceneId, 0);
      }
    }
  }
  
  // Display selected example
  function displayMVExample(sceneId, exampleIndex) {
    const example = mvScanQAData[sceneId][exampleIndex];
    
    if (!example) return;
    
    // Update Question 1
    document.getElementById('mvQuestion1').textContent = example.question_1;
    document.getElementById('mvAnswer1').textContent = example.answers_1[0];
    document.getElementById('mvObjects1').textContent = 
      example.object_names_1.join(', ');
    
    // Update Question 2
    document.getElementById('mvQuestion2').textContent = example.question_2;
    document.getElementById('mvAnswer2').textContent = example.answers_2[0];
    document.getElementById('mvObjects2').textContent = 
      example.object_names_2.join(', ');
    
    // Update Composite Question
    document.getElementById('mvNewQuestion').textContent = example.new_question;
    document.getElementById('mvNewAnswer').textContent = example.new_answer;
    
    // Merge and deduplicate objects
    const allObjectIds = [...new Set([...example.object_ids_1, ...example.object_ids_2])];
    const allObjectNames = [...new Set([...example.object_names_1, ...example.object_names_2])];
    document.getElementById('mvAllObjects').textContent = allObjectNames.join(', ');
    
    // Update view requirements
    const viewsRequired = example.n_views_can_solve + 1; // Add 1 because it's minus-ed
    const viewsText = viewsRequired === 1 ? '1 View' : `${viewsRequired} Views`;
    document.getElementById('mvViewsRequired').innerHTML = 
      `<span class="tag is-large ${viewsRequired > 1 ? 'is-danger' : 'is-success'}">${viewsText}</span>`;
    
    // Update overlap score
    const overlapMean = (example.best_view_overlap_mean * 100).toFixed(1);
    document.getElementById('mvOverlapScore').innerHTML = 
      `<span class="tag is-medium is-info">${overlapMean}%</span>`;
  }
  
  // Fallback data
  function loadMVFallbackData() {
    mvScanQAData = {
      "scene0000_00": [{
        "scene_id": "scene0000_00",
        "question_1": "Where is the green chair located?",
        "answers_1": ["at table", "at table", "at table"],
        "object_ids_1": [9, 10, 16],
        "object_names_1": ["table", "table", "chair"],
        "question_2": "How many green chairs does the brown table face?",
        "answers_2": ["2"],
        "object_ids_2": [5, 16],
        "object_names_2": ["chair", "chair"],
        "new_question": "How many green chairs are located at the table?",
        "new_answer": "2 green chairs",
        "n_views_can_solve": 0,
        "best_view_overlap_mean": 0.987
      }]
    };
    
    updateMVExampleOptions("scene0000_00");
  }
  
  // Initialize on page load
  document.addEventListener('DOMContentLoaded', async function() {
    // Load MV-ScanQA data
    await loadMVScanQAAnnotations();
    
    // Scene selector event
    document.getElementById('mvScanQASceneSelector').addEventListener('change', function(e) {
      updateMVExampleOptions(e.target.value);
    });
    
    // Example selector event
    document.getElementById('mvScanQAExampleSelector').addEventListener('change', function(e) {
      const sceneId = document.getElementById('mvScanQASceneSelector').value;
      displayMVExample(sceneId, parseInt(e.target.value));
    });
  });
  </script>


<!-- TripAlign Dataset Examples -->
<section class="section" style="background-color: #f5f5f5;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">TripAlign Dataset Examples (Static)</h2>
        <div class="content has-text-justified">
          <p>
            TripAlign provides rich multi-object contextual alignments between 2D views, a set of visible 3D objects, and natural language descriptions. 
            Each triplet captures semantically related objects with their spatial relationships.
          </p>
        </div>
      </div>
    </div>

    <!-- Figure Display -->
    <div class="columns is-centered" style="margin-top: 2rem;">
      <div class="column is-full">
        <figure class="image">
          <img src="static/images/qual-vc.png"
               alt="TripAlign Dataset Examples" 
               style="max-width: 100%; height: auto; border: 1px solid #ddd; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
        </figure>
        <div class="content has-text-centered" style="margin-top: 1rem;">
          <p class="is-size-6 has-text-grey">
            <em>Figure: TripAlign examples showing the alignment between 2D views, 3D object groups, and textual descriptions. 
            Each triplet provides rich contextual information about multiple related objects.</em>
          </p>
        </div>
      </div>
    </div>

    <!-- Dataset Characteristics -->
    <div class="columns is-multiline is-centered" style="margin-top: 2rem;">
      <div class="column is-4">
        <div class="box has-text-centered">
          <p class="title is-5 has-text-warning">Multi-Object</p>
          <p class="subtitle is-6">Groups of contextually related objects</p>
        </div>
      </div>
      <div class="column is-4">
        <div class="box has-text-centered">
          <p class="title is-5 has-text-danger">View-Grounded</p>
          <p class="subtitle is-6">Explicit 2D-3D correspondence</p>
        </div>
      </div>
      <div class="column is-4">
        <div class="box has-text-centered">
          <p class="title is-5 has-text-link">Low-Cost</p>
          <p class="subtitle is-6">Automated generation pipeline</p>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- TripAlign Dataset Showcase -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">TripAlign Dataset Showcase</h2>
        <div class="content has-text-justified">
          <p>
            TripAlign contains 1M triplets of &lt;2D view, 3D objects, text&gt; that provide rich multimodal alignment signals. 
            Each triplet captures contextually related objects from multiple viewpoints with detailed textual descriptions.
          </p>
        </div>
      </div>
    </div>

    <!-- Interactive Data Viewer -->
    <div class="columns is-centered" style="margin-top: 2rem;">
      <div class="column is-full">
        <!-- Controls -->
        <div class="field is-grouped is-grouped-centered" style="margin-bottom: 2rem;">
          <div class="control">
            <label class="label">Scene:</label>
            <div class="select">
              <select id="tripAlignSceneSelector">
                <!-- Options will be populated dynamically -->
              </select>
            </div>
          </div>
          <div class="control">
            <label class="label">Triplet:</label>
            <div class="select">
              <select id="tripAlignTripletSelector">
                <option value="triplet_0">Triplet 1</option>
                <option value="triplet_1">Triplet 2</option>
                <option value="triplet_2">Triplet 3</option>
                <option value="triplet_3">Triplet 4</option>
              </select>
            </div>
          </div>
          <div class="control">
            <label class="label">Debug:</label>
            <label class="checkbox">
              <input type="checkbox" id="showAxes" checked>
              Show Axes
            </label>
          </div>
        </div>

        <!-- Main Visualization Area -->
        <div class="columns">
          <!-- 2D View -->
          <div class="column is-half">
            <div class="box">
              <h4 class="title is-5 has-text-centered">2D View</h4>
              <figure class="image">
                <img id="tripAlign2DView" src="static/tripalign/images/scene0000_00/color/0.jpg" 
                     alt="2D View" style="border-radius: 8px;">
              </figure>
              <div class="content" style="margin-top: 1rem;">
                <p class="has-text-centered is-size-7">
                  <strong>Frame Info:</strong> <span id="cameraInfo">Position: (2.1, 1.5, -3.2), Rotation: (15°, -45°, 0°)</span>
                </p>
              </div>
            </div>
          </div>

          <!-- 3D Scene -->
          <div class="column is-half">
            <div class="box">
              <h4 class="title is-5 has-text-centered">3D Scene</h4>
              <div style="position: relative;">
                <!-- Updated loading container with progress bar -->
                <div id="tripAlignLoading" class="progress-container">
                  <div class="progress-text">Loading 3D Scene...</div>
                  <progress id="loadingProgress" class="progress is-primary" value="0" max="100">0%</progress>
                  <div class="progress-text"><span id="progressPercent">0</span>%</div>
                  <div class="progress-note">The 3D scene (100~500MB) may take minutes to load from HuggingFace.</div>
                </div>
                <canvas id="tripAlign3DScene" style="width: 100%; height: 300px; border-radius: 8px; background-color: #f8f9fa;"></canvas>
              </div>
              <div class="content" style="margin-top: 1rem;">
                <p class="has-text-centered is-size-7" style="display: none;">
                  <strong>Highlighted Objects:</strong> <span id="objectInfo">Sofa, Coffee Table, TV Stand</span>
                </p>
                <p class="has-text-centered is-size-7">
                  <em>Drag to rotate • Scroll to zoom • Right-click to pan</em>
                </p>
              </div>
            </div>
          </div>
        </div>

        <!-- Text Description -->
        <div class="columns is-centered">
          <div class="column is-four-fifths">
            <div class="box">
              <h4 class="title is-5 has-text-centered">Contextual Description</h4>
              <div class="content">
                <blockquote id="tripAlignText" style="font-size: 1.1em; line-height: 1.6; border-left: 4px solid #3273dc; padding-left: 1rem;">
                  "In this cozy living room scene, there is a comfortable brown leather sofa positioned against the wall, 
                  with a wooden coffee table placed in front of it. The coffee table has some magazines and a small plant on top. 
                  To the right, there's a modern TV stand holding a flat-screen television. The spatial arrangement creates 
                  a typical entertainment area where the sofa faces the TV, with the coffee table serving as a functional 
                  surface between them."
                </blockquote>
              </div>
              <div class="tags is-centered">
                <span class="tag is-primary">Spatial Relations</span>
                <span class="tag is-info">Object Properties</span>
                <span class="tag is-success">Contextual Understanding</span>
                <span class="tag is-warning">Multi-Object Alignment</span>
              </div>
            </div>
          </div>
        </div>

        <!-- Statistics -->
        <div class="columns is-multiline is-centered" style="margin-top: 2rem;">
          <div class="column is-3 is-offset-1-tablet">
            <div class="box has-text-centered">
              <p class="title is-4 has-text-primary">1M</p>
              <p class="subtitle is-6">Total Triplets</p>
            </div>
          </div>
          <div class="column is-3">
            <div class="box has-text-centered">
              <p class="title is-4 has-text-info">1513</p>
              <p class="subtitle is-6">Unique Scenes</p>
            </div>
          </div>
          <div class="column is-3">
            <div class="box has-text-centered">
              <p class="title is-4 has-text-success">3.2</p>
              <p class="subtitle is-6">Avg. Objects in Triplet <br/> (Well Visible)</p>
            </div>
          </div>
        </div>


        <div class="content has-text-centered" style="margin-top: 1rem;">
          <p class="is-size-7 has-text-grey">
            <em>Note: Use the dropdown menus to explore different scenes and triplets. 
            The 3D viewer supports mouse interaction for rotation and zoom.</em>
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- THREE.js and required libraries -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/controls/OrbitControls.js"></script>
<script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/loaders/PLYLoader.js"></script>
<script src="static/js/shared3DSceneManager.js"></script>


<!-- JavaScript for TripAlign Visualization -->
<script>
  // const HF_REPO = "https://huggingface.co/datasets/kmichiru/scannet_samples/resolve/main"
  const HF_REPO = "https://huggingface.co/datasets/kmichiru/scannet_samples/resolve/main"

  // Updated data structure for TripAlign
  const tripAlignDataBackup = {
    "scene0000_00": {
      "triplet_0": {
        "2d_image": "0",
        // "3d_model": "static/tripalign/scene/scene0000_00/scene0000_00_vh_clean.ply",
        "text": "In this cozy living room scene, there is a comfortable brown leather sofa positioned against the wall, with a wooden coffee table placed in front of it. The coffee table has some magazines and a small plant on top. To the right, there's a modern TV stand holding a flat-screen television. The spatial arrangement creates a typical entertainment area where the sofa faces the TV, with the coffee table serving as a functional surface between them.",
        "camera_info": "Position: (2.1, 1.5, -3.2), Rotation: (15°, -45°, 0°)",
        "objects": "Sofa, Coffee Table, TV Stand"
      },
      "triplet_1": {
        "2d_image": "20",
        // "3d_model": "static/tripalign/scene/scene0000_00/scene0000_00_vh_clean.ply",
        "text": "From this angle, we can see the dining area adjacent to the living room. A rectangular wooden dining table is surrounded by four matching chairs. Above the table hangs a modern pendant light fixture. The chairs are neatly arranged around the table, creating an inviting space for family meals and gatherings.",
        "camera_info": "Position: (-1.8, 2.0, 1.5), Rotation: (20°, 135°, 0°)",
        "objects": "Dining Table, Chairs, Pendant Light"
      },
      "triplet_2": {
        "2d_image": "40",
        // "3d_model": "static/tripalign/scene/scene0000_00/scene0000_00_vh_clean.ply",
        "text": "This view captures the corner reading nook with a comfortable armchair positioned next to a tall bookshelf. A small side table holds a reading lamp and a cup of coffee. The bookshelf is filled with various books and decorative items, creating a cozy atmosphere for reading and relaxation.",
        "camera_info": "Position: (3.5, 1.2, 2.8), Rotation: (10°, -60°, 0°)",
        "objects": "Armchair, Bookshelf, Side Table, Reading Lamp"
      }
    },
    "scene0013_00": {
      "triplet_0": {
        "2d_image": "0",
        // "3d_model": "static/tripalign/scene/scene0001_00/scene0001_00_vh_clean.ply",
        "text": "The modern kitchen features a large central island with bar stools arranged along one side. The island serves as both a preparation area and casual dining space. Pendant lights hang above the island, providing focused illumination for cooking and dining activities.",
        "camera_info": "Position: (0.5, 2.5, -4.0), Rotation: (25°, 0°, 0°)",
        "objects": "Kitchen Island, Bar Stools, Pendant Lights"
      }
    },
    "scene0029_00": {
      "triplet_0": {
        "2d_image": "0",
        // "3d_model": "static/tripalign/scene/scene0002_00/scene0002_00_vh_clean.ply",
        "text": "A spacious bedroom with a queen-size bed positioned against the main wall. Two nightstands flank the bed, each topped with matching table lamps. A large dresser sits opposite the bed, with a mirror mounted above it.",
        "camera_info": "Position: (4.2, 1.8, -2.1), Rotation: (12°, -30°, 0°)",
        "objects": "Bed, Nightstands, Dresser, Mirror"
      }
    }
  };

  let tripAlignData = {};
  // let mvScanQAData = {};

  // 添加加载JSON数据的函数
  async function loadTripAlignAnnotations() {
    try {
      const response = await fetch('static/tripalign/sampled_annotations.json');
      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }
      
      const annotations = await response.json();
      console.log(`Loaded ${annotations.length} annotations`);
      
      // 将数据转换为原来的格式
      tripAlignData = {};
      
      // 按场景分组
      annotations.forEach((item, index) => {
        const sceneId = item.scene_id;
        
        if (!tripAlignData[sceneId]) {
          tripAlignData[sceneId] = {};
        }
        
        // 计算该场景中的triplet索引
        const tripletCount = Object.keys(tripAlignData[sceneId]).length;
        const tripletId = `triplet_${tripletCount}`;
        
        // 提取frame编号（去掉.jpg后缀）
        const frameNumber = item.frame_id.replace('.jpg', '');

        // If not itm_score, set to 'N/A', otherwise set to 3 decimal places
        if (typeof item.itm_score !== 'number') {
          item.itm_score = 'N/A';
        } else if (item.itm_score < 0 || item.itm_score > 1) {
          item.itm_score = 'N/A';
        } else {
          item.itm_score = item.itm_score.toFixed(3);
        }
        
        tripAlignData[sceneId][tripletId] = {
          "2d_image": `static/tripalign/images/${sceneId}/color/${frameNumber}.jpg`,
          "3d_model": `${HF_REPO}/${sceneId}_vh_clean.ply`,
          "text": item.description,
          "camera_info": `Frame: ${item.frame_id}, ITM Score: ${item.itm_score}`,
          "objects": "Objects detected in scene" // 可以后续从描述中提取
        };
      });
      
      console.log('Processed tripAlign data:', tripAlignData);
      
      // 更新场景选择器
      populateSceneSelector();
      
      // 加载第一个场景
      const firstSceneId = Object.keys(tripAlignData)[0];
      if (firstSceneId) {
        document.getElementById('tripAlignSceneSelector').value = firstSceneId;
        updateTripletOptions(firstSceneId);
      }
      
    } catch (error) {
      console.error('Error loading annotations:', error);
      
      // 如果加载失败，使用备用数据
      tripAlignData = tripAlignDataBackup;

      populateSceneSelector();
      const firstSceneId = Object.keys(tripAlignData)[0];
      if (firstSceneId) {
        document.getElementById('tripAlignSceneSelector').value = firstSceneId;
        updateTripletOptions(firstSceneId);
      }
    }
  }

  // Replace static file with HF_REPO
  for (const sceneId in tripAlignData) {
    for (const tripletId in tripAlignData[sceneId]) {
      const triplet = tripAlignData[sceneId][tripletId];
      // let scene_file = triplet["3d_model"].split("/").at(-1);
      const scene_file = `${sceneId}_vh_clean.ply`;
      triplet["3d_model"] = HF_REPO + "/" + scene_file;
      triplet["2d_image"] = `static/tripalign/images/${sceneId}/color/${triplet["2d_image"]}.jpg`;

      console.log(`Updated 3D model path for ${sceneId} ${tripletId}: ${triplet["3d_model"]}`);
    }
  }

  // 3D Scene variables
  let scene, camera, renderer, controls;
  let currentModel = null;
  let currentSceneId = null;
  let currentAlignmentMatrix = null; // Store alignment matrix
  let plyLoader;
  let modelCenter = new THREE.Vector3();
  let modelSize = 0;

  // Alignment matrix cache
  const alignmentMatrixCache = {};
  
  // Geometry cache for loaded models
  let geometryCache = {};
  let loadingPromises = {};

  function init3DScene() {
    const canvas = document.getElementById('tripAlign3DScene');
    
    // Scene setup
    scene = new THREE.Scene();
    scene.background = new THREE.Color(0xf8f9fa);
    
    // Camera setup
    camera = new THREE.PerspectiveCamera(60, canvas.offsetWidth / canvas.offsetHeight, 0.1, 1000);
    
    // Renderer setup
    renderer = new THREE.WebGLRenderer({ 
      canvas: canvas, 
      antialias: true,
      alpha: true 
    });
    renderer.setSize(canvas.offsetWidth, canvas.offsetHeight);
    renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
    renderer.shadowMap.enabled = true;
    renderer.shadowMap.type = THREE.PCFSoftShadowMap;
    renderer.outputEncoding = THREE.sRGBEncoding;
    renderer.toneMapping = THREE.ACESFilmicToneMapping;
    renderer.toneMappingExposure = 1.2;
    
    // Enhanced ambient lighting setup
    setupLighting();
    
    // Add debug axes
    addDebugAxes();
    
    // Controls setup
    controls = new THREE.OrbitControls(camera, canvas);
    controls.enableDamping = true;
    controls.dampingFactor = 0.05;
    controls.enableZoom = true;
    controls.enablePan = true;
    controls.maxPolarAngle = Math.PI;
    controls.minDistance = 0.5;
    controls.maxDistance = 50;
    controls.autoRotate = false;
    controls.autoRotateSpeed = 0.5;
    
    // PLY Loader setup
    plyLoader = new THREE.PLYLoader();
    
    // Animation loop
    function animate() {
      requestAnimationFrame(animate);
      controls.update();
      renderer.render(scene, camera);
    }
    animate();
    
    console.log('3D Scene initialized successfully');
  }

  // Calculate mass center (average position) of all vertices with sampling for large point clouds
  function calculateMassCenter(geometry) {
    const positions = geometry.attributes.position;
    const vertexCount = positions.count;
    
    // Use sampling for large point clouds to improve performance
    const maxSampleSize = 50000; // Sample at most 50k points
    const sampleStep = Math.max(1, Math.floor(vertexCount / maxSampleSize));
    const actualSampleSize = Math.floor(vertexCount / sampleStep);
    
    console.log(`Calculating mass center: ${vertexCount} total vertices, sampling every ${sampleStep} (${actualSampleSize} samples)`);
    
    let sumX = 0, sumY = 0, sumZ = 0;
    let sampleCount = 0;
    
    // Sample vertices to calculate average position
    for (let i = 0; i < vertexCount; i += sampleStep) {
      sumX += positions.getX(i);
      sumY += positions.getY(i);
      sumZ += positions.getZ(i);
      sampleCount++;
    }
    
    const massCenter = new THREE.Vector3(
      sumX / sampleCount,
      sumY / sampleCount,
      sumZ / sampleCount
    );
    
    console.log(`Mass center calculated from ${sampleCount} samples:`, massCenter);
    return massCenter;
  }

  // Calculate bounding box size for scaling (still needed for scale calculation)
  function calculateBoundingSize(geometry) {
    const positions = geometry.attributes.position;
    const vertexCount = positions.count;
    
    // Use sampling for large point clouds
    const maxSampleSize = 10000; // Smaller sample for bounding box
    const sampleStep = Math.max(1, Math.floor(vertexCount / maxSampleSize));
    
    let minX = Infinity, minY = Infinity, minZ = Infinity;
    let maxX = -Infinity, maxY = -Infinity, maxZ = -Infinity;
    
    // Sample vertices to find bounds
    for (let i = 0; i < vertexCount; i += sampleStep) {
      const x = positions.getX(i);
      const y = positions.getY(i);
      const z = positions.getZ(i);
      
      minX = Math.min(minX, x);
      minY = Math.min(minY, y);
      minZ = Math.min(minZ, z);
      maxX = Math.max(maxX, x);
      maxY = Math.max(maxY, y);
      maxZ = Math.max(maxZ, z);
    }
    
    const size = new THREE.Vector3(
      maxX - minX,
      maxY - minY,
      maxZ - minZ
    );
    
    const maxSize = Math.max(size.x, size.y, size.z);
    console.log(`Bounding size calculated from sampling:`, size, `Max dimension: ${maxSize}`);
    
    return maxSize;
  }

  function setupLighting() {
    // Remove existing lights
    const existingLights = scene.children.filter(child => child.isLight);
    existingLights.forEach(light => scene.remove(light));
    
    // High-quality ambient lighting
    const ambientLight = new THREE.AmbientLight(0x404040, 0.6);
    scene.add(ambientLight);
    
    // Main directional light from above (following ScanNet Y-up convention)
    const mainLight = new THREE.DirectionalLight(0xffffff, 0.8);
    mainLight.position.set(0, 10, 0);
    mainLight.castShadow = true;
    mainLight.shadow.mapSize.width = 2048;
    mainLight.shadow.mapSize.height = 2048;
    mainLight.shadow.camera.near = 0.5;
    mainLight.shadow.camera.far = 50;
    mainLight.shadow.camera.left = -10;
    mainLight.shadow.camera.right = 10;
    mainLight.shadow.camera.top = 10;
    mainLight.shadow.camera.bottom = -10;
    scene.add(mainLight);
    
    // Fill lights from sides
    const fillLight1 = new THREE.DirectionalLight(0xffffff, 0.3);
    fillLight1.position.set(5, 5, 0);
    scene.add(fillLight1);
    
    const fillLight2 = new THREE.DirectionalLight(0xffffff, 0.3);
    fillLight2.position.set(-5, 5, 0);
    scene.add(fillLight2);
    
    const fillLight3 = new THREE.DirectionalLight(0xffffff, 0.3);
    fillLight3.position.set(0, 5, 5);
    scene.add(fillLight3);
    
    const fillLight4 = new THREE.DirectionalLight(0xffffff, 0.3);
    fillLight4.position.set(0, 5, -5);
    scene.add(fillLight4);
    
    // Hemisphere light for natural ambient lighting
    const hemisphereLight = new THREE.HemisphereLight(0x87CEEB, 0x8B7355, 0.4);
    scene.add(hemisphereLight);
    
    console.log('Enhanced lighting setup complete');
  }

  function addDebugAxes() {
    // Remove existing axes if any
    const existingAxes = scene.children.filter(child => child.name === 'debugAxes');
    existingAxes.forEach(axes => scene.remove(axes));
    
    // Create axes helper
    const axesHelper = new THREE.AxesHelper(2);
    axesHelper.name = 'debugAxes';
    scene.add(axesHelper);
    
    // Create text labels
    const createTextSprite = (text, color, position) => {
      const canvas = document.createElement('canvas');
      const context = canvas.getContext('2d');
      canvas.width = 64;
      canvas.height = 64;
      
      context.fillStyle = color;
      context.font = 'Bold 32px Arial';
      context.textAlign = 'center';
      context.fillText(text, 32, 40);
      
      const texture = new THREE.CanvasTexture(canvas);
      const spriteMaterial = new THREE.SpriteMaterial({ map: texture });
      const sprite = new THREE.Sprite(spriteMaterial);
      sprite.position.copy(position);
      sprite.scale.set(0.5, 0.5, 1);
      sprite.name = 'debugAxes';
      
      return sprite;
    };
    
    // Add axis labels
    const xLabel = createTextSprite('X', '#ff0000', new THREE.Vector3(2.2, 0, 0));
    const yLabel = createTextSprite('Y', '#00ff00', new THREE.Vector3(0, 2.2, 0));
    const zLabel = createTextSprite('Z', '#0000ff', new THREE.Vector3(0, 0, 2.2));
    
    scene.add(xLabel);
    scene.add(yLabel);
    scene.add(zLabel);
    
    console.log('Debug axes added - ScanNet convention: X(red)=right, Y(green)=up, Z(blue)=forward');
  }

  function toggleAxes(show) {
    const axes = scene.children.filter(child => child.name === 'debugAxes');
    axes.forEach(axis => {
      axis.visible = show;
    });
  }

  function showLoading() {
    document.getElementById('tripAlignLoading').style.display = 'block';
    updateProgress(0);
  }

  function hideLoading() {
    document.getElementById('tripAlignLoading').style.display = 'none';
  }

  function updateProgress(percent) {
    const progressBar = document.getElementById('loadingProgress');
    const progressText = document.getElementById('progressPercent');
    
    progressBar.value = percent;
    progressText.textContent = Math.round(percent);
  }

  // Load alignment matrix from scene text file
  async function loadAlignmentMatrix(sceneId) {
    // Check cache first
    if (alignmentMatrixCache[sceneId]) {
      console.log(`Using cached alignment matrix for ${sceneId}`);
      return alignmentMatrixCache[sceneId];
    }

    try {
      const response = await fetch(`static/tripalign/scene/${sceneId}/${sceneId}.txt`);
      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }
      
      const text = await response.text();
      const lines = text.split('\n');
      
      let axisAlignMatrix = null;
      for (const line of lines) {
        if (line.includes('axisAlignment')) {
          const matrixStr = line.replace('axisAlignment = ', '').trim();
          const values = matrixStr.split(' ').map(x => parseFloat(x));
          
          if (values.length === 16) {
            // Create 4x4 matrix from the values
            axisAlignMatrix = new THREE.Matrix4();
            axisAlignMatrix.set(
              values[0], values[1], values[2], values[3],
              values[4], values[5], values[6], values[7],
              values[8], values[9], values[10], values[11],
              values[12], values[13], values[14], values[15]
            );
            break;
          }
        }
      }
      
      if (!axisAlignMatrix) {
        console.warn(`No axis alignment matrix found for ${sceneId}, using identity`);
        axisAlignMatrix = new THREE.Matrix4(); // Identity matrix
      }
      
      // Cache the result
      alignmentMatrixCache[sceneId] = axisAlignMatrix;
      console.log(`Loaded alignment matrix for ${sceneId}:`, axisAlignMatrix);
      
      return axisAlignMatrix;
      
    } catch (error) {
      console.error(`Error loading alignment matrix for ${sceneId}:`, error);
      // Return identity matrix as fallback
      const identityMatrix = new THREE.Matrix4();
      alignmentMatrixCache[sceneId] = identityMatrix;
      return identityMatrix;
    }
  }

  // Apply alignment transformation to geometry
  function applyAlignmentToGeometry(geometry, alignmentMatrix) {
    // Get the transpose of the alignment matrix (R^T in the formula P' = P * R^T)
    // const alignmentTranspose = alignmentMatrix.clone().transpose();
    const alignmentTranspose = alignmentMatrix; //.clone().transpose();

    
    // Apply transformation to all vertices
    const positions = geometry.attributes.position;
    const vertex = new THREE.Vector3();
    
    for (let i = 0; i < positions.count; i++) {
      vertex.fromBufferAttribute(positions, i);
      vertex.applyMatrix4(alignmentTranspose);
      positions.setXYZ(i, vertex.x, vertex.y, vertex.z);
    }
    
    // Mark positions as needing update
    positions.needsUpdate = true;
    
    // Recompute normals after transformation
    geometry.computeVertexNormals();
    
    console.log('Applied alignment transformation to geometry');
  }

  function downsampleGeometry(geometry, maxVertices = 500_0000) {
    const positions = geometry.attributes.position;
    const vertexCount = positions.count;
    
    if (vertexCount <= maxVertices) {
      console.log(`Geometry has ${vertexCount} vertices, no downsampling needed`);
      return geometry;
    }
    
    // 计算降采样率
    const sampleRate = maxVertices / vertexCount;
    const sampleStep = Math.ceil(1 / sampleRate);
    
    console.log(`Downsampling geometry: ${vertexCount} -> ~${Math.floor(vertexCount / sampleStep)} vertices (step: ${sampleStep})`);
    
    // 创建新的数组来存储降采样后的数据
    const newVertexCount = Math.floor(vertexCount / sampleStep);
    const newPositions = new Float32Array(newVertexCount * 3);
    
    // 如果有颜色属性，也需要降采样
    let newColors = null;
    if (geometry.attributes.color) {
      newColors = new Float32Array(newVertexCount * 3);
    }
    
    // 执行降采样
    let newIndex = 0;
    for (let i = 0; i < vertexCount; i += sampleStep) {
      if (newIndex >= newVertexCount) break;
      
      // 复制位置
      newPositions[newIndex * 3] = positions.getX(i);
      newPositions[newIndex * 3 + 1] = positions.getY(i);
      newPositions[newIndex * 3 + 2] = positions.getZ(i);
      
      // 复制颜色（如果有）
      if (geometry.attributes.color && newColors) {
        const colors = geometry.attributes.color;
        newColors[newIndex * 3] = colors.getX(i);
        newColors[newIndex * 3 + 1] = colors.getY(i);
        newColors[newIndex * 3 + 2] = colors.getZ(i);
      }
      
      newIndex++;
    }
    
    // 创建新的geometry
    const downsampledGeometry = new THREE.BufferGeometry();
    downsampledGeometry.setAttribute('position', new THREE.BufferAttribute(newPositions, 3));
    
    if (newColors) {
      downsampledGeometry.setAttribute('color', new THREE.BufferAttribute(newColors, 3));
    }
    
    console.log(`Downsampling complete: ${newIndex} vertices retained`);
    
    return downsampledGeometry;
  }

  // Updated function to center and scale model using mass center
  function centerAndScaleModel(mesh) {
    console.log('Centering and scaling model using mass center...');
    
    // Get geometry from mesh
    const geometry = mesh.geometry;
    
    // Calculate mass center (average position of vertices)
    const massCenter = calculateMassCenter(geometry);
    
    // Calculate bounding size for scaling
    const boundingSize = calculateBoundingSize(geometry);
    
    // Store model info
    modelCenter.copy(massCenter);
    modelSize = boundingSize;
    
    // Center the model at origin using mass center
    mesh.position.set(-massCenter.x, -massCenter.y, -massCenter.z);
    
    // Scale the model to fit nicely in view
    const targetSize = 4;
    const scale = targetSize / boundingSize;
    mesh.scale.setScalar(scale);
    
    // Update stored size after scaling
    modelSize = targetSize;
    
    console.log(`Model centered at mass center: ${massCenter.x.toFixed(2)}, ${massCenter.y.toFixed(2)}, ${massCenter.z.toFixed(2)}`);
    console.log(`Model scaled by factor: ${scale.toFixed(4)}`);
    
    return { 
      center: new THREE.Vector3(0, 0, 0), // After centering, it's at origin
      size: targetSize,
      originalMassCenter: massCenter,
      originalSize: boundingSize,
      scaleFactor: scale
    };
  }

  function setupBirdEyeView() {
    // ScanNet coordinate system: X-right, Y-up, Z-forward
    const height = modelSize * 1.0;
    
    // Set camera position directly above the scene center
    camera.position.set(0, 0, height);
    
    // Look down at the scene center
    controls.target.set(0, 0, 0);
    
    // Set the up vector for proper orientation
    camera.up.set(0, 1, 0);
    
    // Update controls
    controls.update();
    
    console.log(`Bird's eye view setup: Camera at (0, ${height}, 0) looking down at (0, 0, 0)`);
  }

  async function loadPLYModel(modelPath, sceneId) {
    showLoading();
    
    // Remove existing model
    if (currentModel) {
      scene.remove(currentModel);
      currentModel = null;
    }
    
    try {
      // Load alignment matrix first
      const alignmentMatrix = await loadAlignmentMatrix(sceneId);
      currentAlignmentMatrix = alignmentMatrix;
      
      // Create cache key
      const cacheKey = `${sceneId}_${modelPath}`;
      
      // Check if already loading
      if (loadingPromises[cacheKey]) {
        console.log(`Model ${cacheKey} is already loading, waiting...`);
        await loadingPromises[cacheKey];
      }
      
      // Check cache
      if (geometryCache[cacheKey]) {
        console.log(`Using cached geometry for ${cacheKey}`);
        
        // Use cached geometry
        const cachedGeometry = geometryCache[cacheKey];
        
        // Create material
        let material;
        if (cachedGeometry.attributes.color) {
          material = new THREE.MeshLambertMaterial({ 
            vertexColors: true,
            side: THREE.DoubleSide
          });
        } else {
          material = new THREE.MeshLambertMaterial({ 
            color: 0x888888,
            side: THREE.DoubleSide
          });
        }
        
        // Create new mesh
        const mesh = new THREE.Mesh(cachedGeometry, material);
        mesh.castShadow = true;
        mesh.receiveShadow = true;
        
        // Center and scale the model
        const modelInfo = centerAndScaleModel(mesh);
        
        currentModel = mesh;
        scene.add(currentModel);
        
        // Setup camera
        setupBirdEyeView();
        
        hideLoading();
        
        console.log(`Loaded model from cache: ${cacheKey}`);
        return;
      }
      
      // If not cached, create loading promise
      loadingPromises[cacheKey] = new Promise((resolve, reject) => {
        // Load PLY model
        plyLoader.load(
          modelPath,
          function(geometry) {
            console.log('PLY model loaded successfully');
            console.log(`Geometry has ${geometry.attributes.position.count} vertices`);
            
            // Apply alignment transformation to geometry
            applyAlignmentToGeometry(geometry, alignmentMatrix);

            // Downsample geometry if too large
            geometry = downsampleGeometry(geometry); 

            
            // Compute normals if they don't exist
            if (!geometry.attributes.normal) {
              geometry.computeVertexNormals();
            }
            
            // Cache the processed geometry
            geometryCache[cacheKey] = geometry;
            console.log(`Cached geometry for ${cacheKey}, cache size: ${Object.keys(geometryCache).length}`);
            
            // Create material with better lighting response
            let material;
            if (geometry.attributes.color) {
              material = new THREE.MeshLambertMaterial({ 
                vertexColors: true,
                side: THREE.DoubleSide
              });
            } else {
              material = new THREE.MeshLambertMaterial({ 
                color: 0x888888,
                side: THREE.DoubleSide
              });
            }
            
            // Create mesh
            const mesh = new THREE.Mesh(geometry, material);
            mesh.castShadow = true;
            mesh.receiveShadow = true;
            
            // Center and scale the model using mass center
            const modelInfo = centerAndScaleModel(mesh);
            
            currentModel = mesh;
            scene.add(currentModel);
            
            // Setup bird's eye view camera
            setupBirdEyeView();
            
            // Log model statistics
            console.log('Model statistics:', {
              vertices: geometry.attributes.position.count,
              massCenter: modelInfo.originalMassCenter,
              boundingSize: modelInfo.originalSize,
              scaleFactor: modelInfo.scaleFactor
            });
            
            hideLoading();
            
            // Clear loading promise
            delete loadingPromises[cacheKey];
            resolve();
          },
          function(progress) {
            if (progress.total > 0) {
              const percent = (progress.loaded / progress.total * 100);
              console.log('Loading progress:', percent.toFixed(1) + '%');
              updateProgress(percent);
            }
          },
          function(error) {
            console.error('Error loading PLY model:', error);
            hideLoading();
            
            // Clear loading promise
            delete loadingPromises[cacheKey];
            reject(error);
            
            // Load placeholder if PLY fails
            loadPlaceholder3DScene();
          }
        );
      });
      
      await loadingPromises[cacheKey];
      
    } catch (error) {
      console.error('Error in loadPLYModel:', error);
      hideLoading();
      loadPlaceholder3DScene();
    }
  }

  function loadPlaceholder3DScene() {
    console.log('Loading placeholder 3D scene');
    
    // Remove existing model
    if (currentModel) {
      scene.remove(currentModel);
    }
    
    // Create placeholder 3D objects following ScanNet conventions
    const group = new THREE.Group();
    
    // Sofa (box)
    const sofaGeometry = new THREE.BoxGeometry(2, 0.8, 1);
    const sofaMaterial = new THREE.MeshLambertMaterial({ color: 0x8B4513 });
    const sofa = new THREE.Mesh(sofaGeometry, sofaMaterial);
    sofa.position.set(-2, 0.4, 0);
    sofa.castShadow = true;
    sofa.receiveShadow = true;
    group.add(sofa);
    
    // Coffee table (cylinder)
    const tableGeometry = new THREE.CylinderGeometry(0.8, 0.8, 0.1);
    const tableMaterial = new THREE.MeshLambertMaterial({ color: 0xDEB887 });
    const table = new THREE.Mesh(tableGeometry, tableMaterial);
    table.position.set(0, 0.05, 0);
    table.castShadow = true;
    table.receiveShadow = true;
    group.add(table);
    
    // TV stand (box)
    const tvStandGeometry = new THREE.BoxGeometry(1.5, 0.6, 0.4);
    const tvStandMaterial = new THREE.MeshLambertMaterial({ color: 0x2F4F4F });
    const tvStand = new THREE.Mesh(tvStandGeometry, tvStandMaterial);
    tvStand.position.set(2, 0.3, 0);
    tvStand.castShadow = true;
    tvStand.receiveShadow = true;
    group.add(tvStand);
    
    // Add a floor plane at Y=0
    const planeGeometry = new THREE.PlaneGeometry(8, 8);
    const planeMaterial = new THREE.MeshLambertMaterial({ 
      color: 0xf0f0f0,
      transparent: true,
      opacity: 0.8
    });
    const plane = new THREE.Mesh(planeGeometry, planeMaterial);
    plane.rotation.x = -Math.PI / 2;
    plane.position.y = 0;
    plane.receiveShadow = true;
    group.add(plane);
    
    currentModel = group;
    scene.add(currentModel);
    
    // Center and setup camera for placeholder
    centerAndScaleModel(group);
    setupBirdEyeView();
    
    hideLoading();
  }

  function loadTripletData(sceneId, tripletId) {
    const data = tripAlignData[sceneId]?.[tripletId];
    if (!data) {
      console.warn(`No data found for scene: ${sceneId}, triplet: ${tripletId}`);
      return;
    }
    
    console.log(`Loading triplet data: ${sceneId} - ${tripletId}`);
    
    // Update 2D image
    const img = document.getElementById('tripAlign2DView');
    img.src = data['2d_image'];
    img.onerror = function() {
      console.warn('Failed to load 2D image, using placeholder');
      this.src = 'data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDAwIiBoZWlnaHQ9IjMwMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48cmVjdCB3aWR0aD0iMTAwJSIgaGVpZ2h0PSIxMDAlIiBmaWxsPSIjZGRkIi8+PHRleHQgeD0iNTAlIiB5PSI1MCUiIGZvbnQtZmFtaWx5PSJBcmlhbCIgZm9udC1zaXplPSIxOCIgZmlsbD0iIzk5OSIgdGV4dC1hbmNob3I9Im1pZGRsZSIgZHk9Ii4zZW0iPjJEIFZpZXcgUGxhY2Vob2xkZXI8L3RleHQ+PC9zdmc+';
    };
    
    // Update text description
    document.getElementById('tripAlignText').textContent = data.text;
    
    // Update info
    document.getElementById('cameraInfo').textContent = data.camera_info;
    document.getElementById('objectInfo').textContent = data.objects;
    
    // Check if we need to reload the 3D model (only if scene changed)
    const modelPath = data['3d_model'];
    if (currentSceneId !== sceneId) {
      currentSceneId = sceneId;
      
      // Load 3D model with alignment
      if (modelPath && modelPath.endsWith('.ply')) {
        loadPLYModel(modelPath, sceneId);
      } else {
        console.warn('No valid PLY model found, loading placeholder');
        loadPlaceholder3DScene();
      }
    } else {
      console.log('Same scene, skipping 3D model reload');
    }
  }

  function populateSceneSelector() {
    const sceneSelector = document.getElementById('tripAlignSceneSelector');
    
    // Clear existing options
    sceneSelector.innerHTML = '';
    
    // Populate with scene names from data
    Object.keys(tripAlignData).forEach(sceneId => {
      const option = document.createElement('option');
      option.value = sceneId;
      option.textContent = sceneId;
      sceneSelector.appendChild(option);
    });
    
    console.log('Scene selector populated with', Object.keys(tripAlignData).length, 'scenes');
  }

  function updateTripletOptions(sceneId) {
    const tripletSelector = document.getElementById('tripAlignTripletSelector');
    const triplets = tripAlignData[sceneId];
    
    // Clear existing options
    tripletSelector.innerHTML = '';
    
    if (triplets) {
      Object.keys(triplets).forEach((tripletId, index) => {
        const option = document.createElement('option');
        option.value = tripletId;
        option.textContent = `Triplet ${index + 1}`;
        tripletSelector.appendChild(option);
      });
    }
    
    // Load first triplet
    if (tripletSelector.options.length > 0) {
      tripletSelector.selectedIndex = 0;
      loadTripletData(sceneId, tripletSelector.value);
    }
  }

  // Optional: Cache management functions
  function clearGeometryCache() {
    // Dispose all cached geometries
    Object.values(geometryCache).forEach(geometry => {
      geometry.dispose();
    });
    geometryCache = {};
    console.log('Geometry cache cleared');
  }

  function getCacheStatus() {
    const status = {
      count: Object.keys(geometryCache).length,
      scenes: Object.keys(geometryCache),
      totalVertices: 0
    };
    
    Object.values(geometryCache).forEach(geometry => {
      status.totalVertices += geometry.attributes.position.count;
    });
    
    console.log('Cache status:', status);
    return status;
  }

  // Initialize when DOM is loaded
  document.addEventListener('DOMContentLoaded', async function() {
    console.log('Initializing TripAlign visualization...');
    
    // Initialize 3D scene
    init3DScene();

    await loadTripAlignAnnotations();
  
    // Populate scene selector from data
    populateSceneSelector();
    
    // Load initial data (first scene)
    const firstSceneId = Object.keys(tripAlignData)[0];
    if (firstSceneId) {
      document.getElementById('tripAlignSceneSelector').value = firstSceneId;
      updateTripletOptions(firstSceneId);
    }
    
    // Scene selector event listener
    document.getElementById('tripAlignSceneSelector').addEventListener('change', function(e) {
      const sceneId = e.target.value;
      updateTripletOptions(sceneId);
    });
    
    // Triplet selector event listener
    document.getElementById('tripAlignTripletSelector').addEventListener('change', function(e) {
      const sceneId = document.getElementById('tripAlignSceneSelector').value;
      const tripletId = e.target.value;
      loadTripletData(sceneId, tripletId);
    });
    
    // Debug axes toggle
    document.getElementById('showAxes').addEventListener('change', function(e) {
      toggleAxes(e.target.checked);
    });
    
    // Handle window resize
    window.addEventListener('resize', function() {
      const canvas = document.getElementById('tripAlign3DScene');
      const width = canvas.offsetWidth;
      const height = canvas.offsetHeight;
      
      camera.aspect = width / height;
      camera.updateProjectionMatrix();
      renderer.setSize(width, height);
    });
    
    console.log('TripAlign visualization initialized successfully');
  });

  // document.querySelectorAll('.figure-zoom').forEach(img => {
  //   img.addEventListener('click', function() {
  //     // 创建模态框显示大图
  //     const modal = document.createElement('div');
  //     modal.className = 'modal is-active';
  //     modal.innerHTML = `
  //       <div class="modal-background" onclick="this.parentElement.remove()"></div>
  //       <div class="modal-content">
  //         <p class="image">
  //           <img src="${this.src}" alt="${this.alt}">
  //         </p>
  //       </div>
  //       <button class="modal-close is-large" onclick="this.parentElement.remove()"></button>
  //     `;
  //     document.body.appendChild(modal);
  //   });
  // });
</script>

<!-- End TripAlign Dataset Showcase -->



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{mo2025mvscanqa,
  title={Advancing 3D Scene Understanding with MV-ScanQA Multi-View Reasoning Evaluation and TripAlign Pre-training Dataset},
  author={Mo, Wentao and Chen, QingChao and Peng, Yuxin and Huang, Siyuan and Liu, Yang},
  year={2025},
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
